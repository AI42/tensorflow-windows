// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/config.proto

#define INTERNAL_SUPPRESS_PROTOBUF_FIELD_DEPRECATION
#include "tensorflow/core/framework/config.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/stubs/once.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)

namespace tensorflow {

namespace {

const ::google::protobuf::Descriptor* GPUOptions_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  GPUOptions_reflection_ = NULL;
const ::google::protobuf::Descriptor* OptimizerOptions_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  OptimizerOptions_reflection_ = NULL;
const ::google::protobuf::EnumDescriptor* OptimizerOptions_Level_descriptor_ = NULL;
const ::google::protobuf::Descriptor* GraphOptions_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  GraphOptions_reflection_ = NULL;
const ::google::protobuf::Descriptor* ConfigProto_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  ConfigProto_reflection_ = NULL;
const ::google::protobuf::Descriptor* ConfigProto_DeviceCountEntry_descriptor_ = NULL;

}  // namespace


void protobuf_AssignDesc_tensorflow_2fcore_2fframework_2fconfig_2eproto() {
  protobuf_AddDesc_tensorflow_2fcore_2fframework_2fconfig_2eproto();
  const ::google::protobuf::FileDescriptor* file =
    ::google::protobuf::DescriptorPool::generated_pool()->FindFileByName(
      "tensorflow/core/framework/config.proto");
  GOOGLE_CHECK(file != NULL);
  GPUOptions_descriptor_ = file->message_type(0);
  static const int GPUOptions_offsets_[3] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GPUOptions, per_process_gpu_memory_fraction_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GPUOptions, allocator_type_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GPUOptions, deferred_deletion_bytes_),
  };
  GPUOptions_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      GPUOptions_descriptor_,
      GPUOptions::default_instance_,
      GPUOptions_offsets_,
      -1,
      -1,
      -1,
      sizeof(GPUOptions),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GPUOptions, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GPUOptions, _is_default_instance_));
  OptimizerOptions_descriptor_ = file->message_type(1);
  static const int OptimizerOptions_offsets_[4] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(OptimizerOptions, do_common_subexpression_elimination_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(OptimizerOptions, do_constant_folding_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(OptimizerOptions, do_function_inlining_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(OptimizerOptions, opt_level_),
  };
  OptimizerOptions_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      OptimizerOptions_descriptor_,
      OptimizerOptions::default_instance_,
      OptimizerOptions_offsets_,
      -1,
      -1,
      -1,
      sizeof(OptimizerOptions),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(OptimizerOptions, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(OptimizerOptions, _is_default_instance_));
  OptimizerOptions_Level_descriptor_ = OptimizerOptions_descriptor_->enum_type(0);
  GraphOptions_descriptor_ = file->message_type(2);
  static const int GraphOptions_offsets_[2] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GraphOptions, enable_recv_scheduling_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GraphOptions, optimizer_options_),
  };
  GraphOptions_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      GraphOptions_descriptor_,
      GraphOptions::default_instance_,
      GraphOptions_offsets_,
      -1,
      -1,
      -1,
      sizeof(GraphOptions),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GraphOptions, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GraphOptions, _is_default_instance_));
  ConfigProto_descriptor_ = file->message_type(3);
  static const int ConfigProto_offsets_[10] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, device_count_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, intra_op_parallelism_threads_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, inter_op_parallelism_threads_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, use_per_session_threads_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, placement_period_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, device_filters_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, gpu_options_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, allow_soft_placement_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, log_device_placement_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, graph_options_),
  };
  ConfigProto_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      ConfigProto_descriptor_,
      ConfigProto::default_instance_,
      ConfigProto_offsets_,
      -1,
      -1,
      -1,
      sizeof(ConfigProto),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, _is_default_instance_));
  ConfigProto_DeviceCountEntry_descriptor_ = ConfigProto_descriptor_->nested_type(0);
}

namespace {

GOOGLE_PROTOBUF_DECLARE_ONCE(protobuf_AssignDescriptors_once_);
inline void protobuf_AssignDescriptorsOnce() {
  ::google::protobuf::GoogleOnceInit(&protobuf_AssignDescriptors_once_,
                 &protobuf_AssignDesc_tensorflow_2fcore_2fframework_2fconfig_2eproto);
}

void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      GPUOptions_descriptor_, &GPUOptions::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      OptimizerOptions_descriptor_, &OptimizerOptions::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      GraphOptions_descriptor_, &GraphOptions::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      ConfigProto_descriptor_, &ConfigProto::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
        ConfigProto_DeviceCountEntry_descriptor_,
        ::google::protobuf::internal::MapEntry<
            ::std::string,
            ::google::protobuf::int32,
            ::google::protobuf::internal::WireFormatLite::TYPE_STRING,
            ::google::protobuf::internal::WireFormatLite::TYPE_INT32,
            0>::CreateDefaultInstance(
                ConfigProto_DeviceCountEntry_descriptor_));
}

}  // namespace

void protobuf_ShutdownFile_tensorflow_2fcore_2fframework_2fconfig_2eproto() {
  delete GPUOptions::default_instance_;
  delete GPUOptions_reflection_;
  delete OptimizerOptions::default_instance_;
  delete OptimizerOptions_reflection_;
  delete GraphOptions::default_instance_;
  delete GraphOptions_reflection_;
  delete ConfigProto::default_instance_;
  delete ConfigProto_reflection_;
}

void protobuf_AddDesc_tensorflow_2fcore_2fframework_2fconfig_2eproto() {
  static bool already_here = false;
  if (already_here) return;
  already_here = true;
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
    "\n&tensorflow/core/framework/config.proto"
    "\022\ntensorflow\"n\n\nGPUOptions\022\'\n\037per_proces"
    "s_gpu_memory_fraction\030\001 \001(\001\022\026\n\016allocator"
    "_type\030\002 \001(\t\022\037\n\027deferred_deletion_bytes\030\003"
    " \001(\003\"\333\001\n\020OptimizerOptions\022+\n#do_common_s"
    "ubexpression_elimination\030\001 \001(\010\022\033\n\023do_con"
    "stant_folding\030\002 \001(\010\022\034\n\024do_function_inlin"
    "ing\030\004 \001(\010\0225\n\topt_level\030\003 \001(\0162\".tensorflo"
    "w.OptimizerOptions.Level\"(\n\005Level\022\006\n\002L1\020"
    "\000\022\006\n\002L2\020\002\022\017\n\002L0\020\377\377\377\377\377\377\377\377\377\001\"\224\001\n\014GraphOpti"
    "ons\022\036\n\026enable_recv_scheduling\030\002 \001(\010\0227\n\021o"
    "ptimizer_options\030\003 \001(\0132\034.tensorflow.Opti"
    "mizerOptionsJ\004\010\001\020\002R%skip_common_subexpre"
    "ssion_elimination\"\272\003\n\013ConfigProto\022>\n\014dev"
    "ice_count\030\001 \003(\0132(.tensorflow.ConfigProto"
    ".DeviceCountEntry\022$\n\034intra_op_parallelis"
    "m_threads\030\002 \001(\005\022$\n\034inter_op_parallelism_"
    "threads\030\005 \001(\005\022\037\n\027use_per_session_threads"
    "\030\t \001(\010\022\030\n\020placement_period\030\003 \001(\005\022\026\n\016devi"
    "ce_filters\030\004 \003(\t\022+\n\013gpu_options\030\006 \001(\0132\026."
    "tensorflow.GPUOptions\022\034\n\024allow_soft_plac"
    "ement\030\007 \001(\010\022\034\n\024log_device_placement\030\010 \001("
    "\010\022/\n\rgraph_options\030\n \001(\0132\030.tensorflow.Gr"
    "aphOptions\0322\n\020DeviceCountEntry\022\013\n\003key\030\001 "
    "\001(\t\022\r\n\005value\030\002 \001(\005:\0028\001B*\n\030org.tensorflow"
    ".frameworkB\014ConfigProtosP\001b\006proto3", 1034);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "tensorflow/core/framework/config.proto", &protobuf_RegisterTypes);
  GPUOptions::default_instance_ = new GPUOptions();
  OptimizerOptions::default_instance_ = new OptimizerOptions();
  GraphOptions::default_instance_ = new GraphOptions();
  ConfigProto::default_instance_ = new ConfigProto();
  GPUOptions::default_instance_->InitAsDefaultInstance();
  OptimizerOptions::default_instance_->InitAsDefaultInstance();
  GraphOptions::default_instance_->InitAsDefaultInstance();
  ConfigProto::default_instance_->InitAsDefaultInstance();
  ::google::protobuf::internal::OnShutdown(&protobuf_ShutdownFile_tensorflow_2fcore_2fframework_2fconfig_2eproto);
}

// Force AddDescriptors() to be called at static initialization time.
struct StaticDescriptorInitializer_tensorflow_2fcore_2fframework_2fconfig_2eproto {
  StaticDescriptorInitializer_tensorflow_2fcore_2fframework_2fconfig_2eproto() {
    protobuf_AddDesc_tensorflow_2fcore_2fframework_2fconfig_2eproto();
  }
} static_descriptor_initializer_tensorflow_2fcore_2fframework_2fconfig_2eproto_;

namespace {

static void MergeFromFail(int line) GOOGLE_ATTRIBUTE_COLD;
static void MergeFromFail(int line) {
  GOOGLE_CHECK(false) << __FILE__ << ":" << line;
}

}  // namespace


// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int GPUOptions::kPerProcessGpuMemoryFractionFieldNumber;
const int GPUOptions::kAllocatorTypeFieldNumber;
const int GPUOptions::kDeferredDeletionBytesFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

GPUOptions::GPUOptions()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.GPUOptions)
}

void GPUOptions::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

GPUOptions::GPUOptions(const GPUOptions& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.GPUOptions)
}

void GPUOptions::SharedCtor() {
    _is_default_instance_ = false;
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  per_process_gpu_memory_fraction_ = 0;
  allocator_type_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  deferred_deletion_bytes_ = GOOGLE_LONGLONG(0);
}

GPUOptions::~GPUOptions() {
  // @@protoc_insertion_point(destructor:tensorflow.GPUOptions)
  SharedDtor();
}

void GPUOptions::SharedDtor() {
  allocator_type_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (this != default_instance_) {
  }
}

void GPUOptions::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* GPUOptions::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return GPUOptions_descriptor_;
}

const GPUOptions& GPUOptions::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fframework_2fconfig_2eproto();
  return *default_instance_;
}

GPUOptions* GPUOptions::default_instance_ = NULL;

GPUOptions* GPUOptions::New(::google::protobuf::Arena* arena) const {
  GPUOptions* n = new GPUOptions;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void GPUOptions::Clear() {
  per_process_gpu_memory_fraction_ = 0;
  allocator_type_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  deferred_deletion_bytes_ = GOOGLE_LONGLONG(0);
}

bool GPUOptions::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.GPUOptions)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional double per_process_gpu_memory_fraction = 1;
      case 1: {
        if (tag == 9) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   double, ::google::protobuf::internal::WireFormatLite::TYPE_DOUBLE>(
                 input, &per_process_gpu_memory_fraction_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_allocator_type;
        break;
      }

      // optional string allocator_type = 2;
      case 2: {
        if (tag == 18) {
         parse_allocator_type:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_allocator_type()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->allocator_type().data(), this->allocator_type().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.GPUOptions.allocator_type"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(24)) goto parse_deferred_deletion_bytes;
        break;
      }

      // optional int64 deferred_deletion_bytes = 3;
      case 3: {
        if (tag == 24) {
         parse_deferred_deletion_bytes:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, &deferred_deletion_bytes_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.GPUOptions)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.GPUOptions)
  return false;
#undef DO_
}

void GPUOptions::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.GPUOptions)
  // optional double per_process_gpu_memory_fraction = 1;
  if (this->per_process_gpu_memory_fraction() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteDouble(1, this->per_process_gpu_memory_fraction(), output);
  }

  // optional string allocator_type = 2;
  if (this->allocator_type().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->allocator_type().data(), this->allocator_type().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.GPUOptions.allocator_type");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      2, this->allocator_type(), output);
  }

  // optional int64 deferred_deletion_bytes = 3;
  if (this->deferred_deletion_bytes() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64(3, this->deferred_deletion_bytes(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.GPUOptions)
}

::google::protobuf::uint8* GPUOptions::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.GPUOptions)
  // optional double per_process_gpu_memory_fraction = 1;
  if (this->per_process_gpu_memory_fraction() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteDoubleToArray(1, this->per_process_gpu_memory_fraction(), target);
  }

  // optional string allocator_type = 2;
  if (this->allocator_type().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->allocator_type().data(), this->allocator_type().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.GPUOptions.allocator_type");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        2, this->allocator_type(), target);
  }

  // optional int64 deferred_deletion_bytes = 3;
  if (this->deferred_deletion_bytes() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt64ToArray(3, this->deferred_deletion_bytes(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.GPUOptions)
  return target;
}

int GPUOptions::ByteSize() const {
  int total_size = 0;

  // optional double per_process_gpu_memory_fraction = 1;
  if (this->per_process_gpu_memory_fraction() != 0) {
    total_size += 1 + 8;
  }

  // optional string allocator_type = 2;
  if (this->allocator_type().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->allocator_type());
  }

  // optional int64 deferred_deletion_bytes = 3;
  if (this->deferred_deletion_bytes() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int64Size(
        this->deferred_deletion_bytes());
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void GPUOptions::MergeFrom(const ::google::protobuf::Message& from) {
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const GPUOptions* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const GPUOptions>(
          &from);
  if (source == NULL) {
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
    MergeFrom(*source);
  }
}

void GPUOptions::MergeFrom(const GPUOptions& from) {
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from.per_process_gpu_memory_fraction() != 0) {
    set_per_process_gpu_memory_fraction(from.per_process_gpu_memory_fraction());
  }
  if (from.allocator_type().size() > 0) {

    allocator_type_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.allocator_type_);
  }
  if (from.deferred_deletion_bytes() != 0) {
    set_deferred_deletion_bytes(from.deferred_deletion_bytes());
  }
}

void GPUOptions::CopyFrom(const ::google::protobuf::Message& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void GPUOptions::CopyFrom(const GPUOptions& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool GPUOptions::IsInitialized() const {

  return true;
}

void GPUOptions::Swap(GPUOptions* other) {
  if (other == this) return;
  InternalSwap(other);
}
void GPUOptions::InternalSwap(GPUOptions* other) {
  std::swap(per_process_gpu_memory_fraction_, other->per_process_gpu_memory_fraction_);
  allocator_type_.Swap(&other->allocator_type_);
  std::swap(deferred_deletion_bytes_, other->deferred_deletion_bytes_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata GPUOptions::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = GPUOptions_descriptor_;
  metadata.reflection = GPUOptions_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// GPUOptions

// optional double per_process_gpu_memory_fraction = 1;
void GPUOptions::clear_per_process_gpu_memory_fraction() {
  per_process_gpu_memory_fraction_ = 0;
}
 double GPUOptions::per_process_gpu_memory_fraction() const {
  // @@protoc_insertion_point(field_get:tensorflow.GPUOptions.per_process_gpu_memory_fraction)
  return per_process_gpu_memory_fraction_;
}
 void GPUOptions::set_per_process_gpu_memory_fraction(double value) {
  
  per_process_gpu_memory_fraction_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.GPUOptions.per_process_gpu_memory_fraction)
}

// optional string allocator_type = 2;
void GPUOptions::clear_allocator_type() {
  allocator_type_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 const ::std::string& GPUOptions::allocator_type() const {
  // @@protoc_insertion_point(field_get:tensorflow.GPUOptions.allocator_type)
  return allocator_type_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void GPUOptions::set_allocator_type(const ::std::string& value) {
  
  allocator_type_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:tensorflow.GPUOptions.allocator_type)
}
 void GPUOptions::set_allocator_type(const char* value) {
  
  allocator_type_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:tensorflow.GPUOptions.allocator_type)
}
 void GPUOptions::set_allocator_type(const char* value, size_t size) {
  
  allocator_type_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:tensorflow.GPUOptions.allocator_type)
}
 ::std::string* GPUOptions::mutable_allocator_type() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.GPUOptions.allocator_type)
  return allocator_type_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 ::std::string* GPUOptions::release_allocator_type() {
  
  return allocator_type_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void GPUOptions::set_allocated_allocator_type(::std::string* allocator_type) {
  if (allocator_type != NULL) {
    
  } else {
    
  }
  allocator_type_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), allocator_type);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.GPUOptions.allocator_type)
}

// optional int64 deferred_deletion_bytes = 3;
void GPUOptions::clear_deferred_deletion_bytes() {
  deferred_deletion_bytes_ = GOOGLE_LONGLONG(0);
}
 ::google::protobuf::int64 GPUOptions::deferred_deletion_bytes() const {
  // @@protoc_insertion_point(field_get:tensorflow.GPUOptions.deferred_deletion_bytes)
  return deferred_deletion_bytes_;
}
 void GPUOptions::set_deferred_deletion_bytes(::google::protobuf::int64 value) {
  
  deferred_deletion_bytes_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.GPUOptions.deferred_deletion_bytes)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

const ::google::protobuf::EnumDescriptor* OptimizerOptions_Level_descriptor() {
  protobuf_AssignDescriptorsOnce();
  return OptimizerOptions_Level_descriptor_;
}
bool OptimizerOptions_Level_IsValid(int value) {
  switch(value) {
    case -1:
    case 0:
    case 2:
      return true;
    default:
      return false;
  }
}

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const OptimizerOptions_Level OptimizerOptions::L1;
const OptimizerOptions_Level OptimizerOptions::L2;
const OptimizerOptions_Level OptimizerOptions::L0;
const OptimizerOptions_Level OptimizerOptions::Level_MIN;
const OptimizerOptions_Level OptimizerOptions::Level_MAX;
const int OptimizerOptions::Level_ARRAYSIZE;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int OptimizerOptions::kDoCommonSubexpressionEliminationFieldNumber;
const int OptimizerOptions::kDoConstantFoldingFieldNumber;
const int OptimizerOptions::kDoFunctionInliningFieldNumber;
const int OptimizerOptions::kOptLevelFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

OptimizerOptions::OptimizerOptions()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.OptimizerOptions)
}

void OptimizerOptions::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

OptimizerOptions::OptimizerOptions(const OptimizerOptions& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.OptimizerOptions)
}

void OptimizerOptions::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  do_common_subexpression_elimination_ = false;
  do_constant_folding_ = false;
  do_function_inlining_ = false;
  opt_level_ = 0;
}

OptimizerOptions::~OptimizerOptions() {
  // @@protoc_insertion_point(destructor:tensorflow.OptimizerOptions)
  SharedDtor();
}

void OptimizerOptions::SharedDtor() {
  if (this != default_instance_) {
  }
}

void OptimizerOptions::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* OptimizerOptions::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return OptimizerOptions_descriptor_;
}

const OptimizerOptions& OptimizerOptions::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fframework_2fconfig_2eproto();
  return *default_instance_;
}

OptimizerOptions* OptimizerOptions::default_instance_ = NULL;

OptimizerOptions* OptimizerOptions::New(::google::protobuf::Arena* arena) const {
  OptimizerOptions* n = new OptimizerOptions;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void OptimizerOptions::Clear() {
#define ZR_HELPER_(f) reinterpret_cast<char*>(\
  &reinterpret_cast<OptimizerOptions*>(16)->f)

#define ZR_(first, last) do {\
  ::memset(&first, 0,\
           ZR_HELPER_(last) - ZR_HELPER_(first) + sizeof(last));\
} while (0)

  ZR_(do_common_subexpression_elimination_, opt_level_);

#undef ZR_HELPER_
#undef ZR_

}

bool OptimizerOptions::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.OptimizerOptions)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional bool do_common_subexpression_elimination = 1;
      case 1: {
        if (tag == 8) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &do_common_subexpression_elimination_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(16)) goto parse_do_constant_folding;
        break;
      }

      // optional bool do_constant_folding = 2;
      case 2: {
        if (tag == 16) {
         parse_do_constant_folding:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &do_constant_folding_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(24)) goto parse_opt_level;
        break;
      }

      // optional .tensorflow.OptimizerOptions.Level opt_level = 3;
      case 3: {
        if (tag == 24) {
         parse_opt_level:
          int value;
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   int, ::google::protobuf::internal::WireFormatLite::TYPE_ENUM>(
                 input, &value)));
          set_opt_level(static_cast< ::tensorflow::OptimizerOptions_Level >(value));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(32)) goto parse_do_function_inlining;
        break;
      }

      // optional bool do_function_inlining = 4;
      case 4: {
        if (tag == 32) {
         parse_do_function_inlining:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &do_function_inlining_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.OptimizerOptions)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.OptimizerOptions)
  return false;
#undef DO_
}

void OptimizerOptions::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.OptimizerOptions)
  // optional bool do_common_subexpression_elimination = 1;
  if (this->do_common_subexpression_elimination() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(1, this->do_common_subexpression_elimination(), output);
  }

  // optional bool do_constant_folding = 2;
  if (this->do_constant_folding() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(2, this->do_constant_folding(), output);
  }

  // optional .tensorflow.OptimizerOptions.Level opt_level = 3;
  if (this->opt_level() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteEnum(
      3, this->opt_level(), output);
  }

  // optional bool do_function_inlining = 4;
  if (this->do_function_inlining() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(4, this->do_function_inlining(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.OptimizerOptions)
}

::google::protobuf::uint8* OptimizerOptions::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.OptimizerOptions)
  // optional bool do_common_subexpression_elimination = 1;
  if (this->do_common_subexpression_elimination() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(1, this->do_common_subexpression_elimination(), target);
  }

  // optional bool do_constant_folding = 2;
  if (this->do_constant_folding() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(2, this->do_constant_folding(), target);
  }

  // optional .tensorflow.OptimizerOptions.Level opt_level = 3;
  if (this->opt_level() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteEnumToArray(
      3, this->opt_level(), target);
  }

  // optional bool do_function_inlining = 4;
  if (this->do_function_inlining() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(4, this->do_function_inlining(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.OptimizerOptions)
  return target;
}

int OptimizerOptions::ByteSize() const {
  int total_size = 0;

  // optional bool do_common_subexpression_elimination = 1;
  if (this->do_common_subexpression_elimination() != 0) {
    total_size += 1 + 1;
  }

  // optional bool do_constant_folding = 2;
  if (this->do_constant_folding() != 0) {
    total_size += 1 + 1;
  }

  // optional bool do_function_inlining = 4;
  if (this->do_function_inlining() != 0) {
    total_size += 1 + 1;
  }

  // optional .tensorflow.OptimizerOptions.Level opt_level = 3;
  if (this->opt_level() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::EnumSize(this->opt_level());
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void OptimizerOptions::MergeFrom(const ::google::protobuf::Message& from) {
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const OptimizerOptions* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const OptimizerOptions>(
          &from);
  if (source == NULL) {
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
    MergeFrom(*source);
  }
}

void OptimizerOptions::MergeFrom(const OptimizerOptions& from) {
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from.do_common_subexpression_elimination() != 0) {
    set_do_common_subexpression_elimination(from.do_common_subexpression_elimination());
  }
  if (from.do_constant_folding() != 0) {
    set_do_constant_folding(from.do_constant_folding());
  }
  if (from.do_function_inlining() != 0) {
    set_do_function_inlining(from.do_function_inlining());
  }
  if (from.opt_level() != 0) {
    set_opt_level(from.opt_level());
  }
}

void OptimizerOptions::CopyFrom(const ::google::protobuf::Message& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void OptimizerOptions::CopyFrom(const OptimizerOptions& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool OptimizerOptions::IsInitialized() const {

  return true;
}

void OptimizerOptions::Swap(OptimizerOptions* other) {
  if (other == this) return;
  InternalSwap(other);
}
void OptimizerOptions::InternalSwap(OptimizerOptions* other) {
  std::swap(do_common_subexpression_elimination_, other->do_common_subexpression_elimination_);
  std::swap(do_constant_folding_, other->do_constant_folding_);
  std::swap(do_function_inlining_, other->do_function_inlining_);
  std::swap(opt_level_, other->opt_level_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata OptimizerOptions::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = OptimizerOptions_descriptor_;
  metadata.reflection = OptimizerOptions_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// OptimizerOptions

// optional bool do_common_subexpression_elimination = 1;
void OptimizerOptions::clear_do_common_subexpression_elimination() {
  do_common_subexpression_elimination_ = false;
}
 bool OptimizerOptions::do_common_subexpression_elimination() const {
  // @@protoc_insertion_point(field_get:tensorflow.OptimizerOptions.do_common_subexpression_elimination)
  return do_common_subexpression_elimination_;
}
 void OptimizerOptions::set_do_common_subexpression_elimination(bool value) {
  
  do_common_subexpression_elimination_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.OptimizerOptions.do_common_subexpression_elimination)
}

// optional bool do_constant_folding = 2;
void OptimizerOptions::clear_do_constant_folding() {
  do_constant_folding_ = false;
}
 bool OptimizerOptions::do_constant_folding() const {
  // @@protoc_insertion_point(field_get:tensorflow.OptimizerOptions.do_constant_folding)
  return do_constant_folding_;
}
 void OptimizerOptions::set_do_constant_folding(bool value) {
  
  do_constant_folding_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.OptimizerOptions.do_constant_folding)
}

// optional bool do_function_inlining = 4;
void OptimizerOptions::clear_do_function_inlining() {
  do_function_inlining_ = false;
}
 bool OptimizerOptions::do_function_inlining() const {
  // @@protoc_insertion_point(field_get:tensorflow.OptimizerOptions.do_function_inlining)
  return do_function_inlining_;
}
 void OptimizerOptions::set_do_function_inlining(bool value) {
  
  do_function_inlining_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.OptimizerOptions.do_function_inlining)
}

// optional .tensorflow.OptimizerOptions.Level opt_level = 3;
void OptimizerOptions::clear_opt_level() {
  opt_level_ = 0;
}
 ::tensorflow::OptimizerOptions_Level OptimizerOptions::opt_level() const {
  // @@protoc_insertion_point(field_get:tensorflow.OptimizerOptions.opt_level)
  return static_cast< ::tensorflow::OptimizerOptions_Level >(opt_level_);
}
 void OptimizerOptions::set_opt_level(::tensorflow::OptimizerOptions_Level value) {
  
  opt_level_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.OptimizerOptions.opt_level)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int GraphOptions::kEnableRecvSchedulingFieldNumber;
const int GraphOptions::kOptimizerOptionsFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

GraphOptions::GraphOptions()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.GraphOptions)
}

void GraphOptions::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  optimizer_options_ = const_cast< ::tensorflow::OptimizerOptions*>(&::tensorflow::OptimizerOptions::default_instance());
}

GraphOptions::GraphOptions(const GraphOptions& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.GraphOptions)
}

void GraphOptions::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  enable_recv_scheduling_ = false;
  optimizer_options_ = NULL;
}

GraphOptions::~GraphOptions() {
  // @@protoc_insertion_point(destructor:tensorflow.GraphOptions)
  SharedDtor();
}

void GraphOptions::SharedDtor() {
  if (this != default_instance_) {
    delete optimizer_options_;
  }
}

void GraphOptions::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* GraphOptions::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return GraphOptions_descriptor_;
}

const GraphOptions& GraphOptions::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fframework_2fconfig_2eproto();
  return *default_instance_;
}

GraphOptions* GraphOptions::default_instance_ = NULL;

GraphOptions* GraphOptions::New(::google::protobuf::Arena* arena) const {
  GraphOptions* n = new GraphOptions;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void GraphOptions::Clear() {
  enable_recv_scheduling_ = false;
  if (GetArenaNoVirtual() == NULL && optimizer_options_ != NULL) delete optimizer_options_;
  optimizer_options_ = NULL;
}

bool GraphOptions::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.GraphOptions)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional bool enable_recv_scheduling = 2;
      case 2: {
        if (tag == 16) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &enable_recv_scheduling_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(26)) goto parse_optimizer_options;
        break;
      }

      // optional .tensorflow.OptimizerOptions optimizer_options = 3;
      case 3: {
        if (tag == 26) {
         parse_optimizer_options:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_optimizer_options()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.GraphOptions)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.GraphOptions)
  return false;
#undef DO_
}

void GraphOptions::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.GraphOptions)
  // optional bool enable_recv_scheduling = 2;
  if (this->enable_recv_scheduling() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(2, this->enable_recv_scheduling(), output);
  }

  // optional .tensorflow.OptimizerOptions optimizer_options = 3;
  if (this->has_optimizer_options()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      3, *this->optimizer_options_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.GraphOptions)
}

::google::protobuf::uint8* GraphOptions::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.GraphOptions)
  // optional bool enable_recv_scheduling = 2;
  if (this->enable_recv_scheduling() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(2, this->enable_recv_scheduling(), target);
  }

  // optional .tensorflow.OptimizerOptions optimizer_options = 3;
  if (this->has_optimizer_options()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        3, *this->optimizer_options_, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.GraphOptions)
  return target;
}

int GraphOptions::ByteSize() const {
  int total_size = 0;

  // optional bool enable_recv_scheduling = 2;
  if (this->enable_recv_scheduling() != 0) {
    total_size += 1 + 1;
  }

  // optional .tensorflow.OptimizerOptions optimizer_options = 3;
  if (this->has_optimizer_options()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->optimizer_options_);
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void GraphOptions::MergeFrom(const ::google::protobuf::Message& from) {
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const GraphOptions* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const GraphOptions>(
          &from);
  if (source == NULL) {
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
    MergeFrom(*source);
  }
}

void GraphOptions::MergeFrom(const GraphOptions& from) {
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from.enable_recv_scheduling() != 0) {
    set_enable_recv_scheduling(from.enable_recv_scheduling());
  }
  if (from.has_optimizer_options()) {
    mutable_optimizer_options()->::tensorflow::OptimizerOptions::MergeFrom(from.optimizer_options());
  }
}

void GraphOptions::CopyFrom(const ::google::protobuf::Message& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void GraphOptions::CopyFrom(const GraphOptions& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool GraphOptions::IsInitialized() const {

  return true;
}

void GraphOptions::Swap(GraphOptions* other) {
  if (other == this) return;
  InternalSwap(other);
}
void GraphOptions::InternalSwap(GraphOptions* other) {
  std::swap(enable_recv_scheduling_, other->enable_recv_scheduling_);
  std::swap(optimizer_options_, other->optimizer_options_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata GraphOptions::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = GraphOptions_descriptor_;
  metadata.reflection = GraphOptions_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// GraphOptions

// optional bool enable_recv_scheduling = 2;
void GraphOptions::clear_enable_recv_scheduling() {
  enable_recv_scheduling_ = false;
}
 bool GraphOptions::enable_recv_scheduling() const {
  // @@protoc_insertion_point(field_get:tensorflow.GraphOptions.enable_recv_scheduling)
  return enable_recv_scheduling_;
}
 void GraphOptions::set_enable_recv_scheduling(bool value) {
  
  enable_recv_scheduling_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.GraphOptions.enable_recv_scheduling)
}

// optional .tensorflow.OptimizerOptions optimizer_options = 3;
bool GraphOptions::has_optimizer_options() const {
  return !_is_default_instance_ && optimizer_options_ != NULL;
}
void GraphOptions::clear_optimizer_options() {
  if (GetArenaNoVirtual() == NULL && optimizer_options_ != NULL) delete optimizer_options_;
  optimizer_options_ = NULL;
}
const ::tensorflow::OptimizerOptions& GraphOptions::optimizer_options() const {
  // @@protoc_insertion_point(field_get:tensorflow.GraphOptions.optimizer_options)
  return optimizer_options_ != NULL ? *optimizer_options_ : *default_instance_->optimizer_options_;
}
::tensorflow::OptimizerOptions* GraphOptions::mutable_optimizer_options() {
  
  if (optimizer_options_ == NULL) {
    optimizer_options_ = new ::tensorflow::OptimizerOptions;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.GraphOptions.optimizer_options)
  return optimizer_options_;
}
::tensorflow::OptimizerOptions* GraphOptions::release_optimizer_options() {
  
  ::tensorflow::OptimizerOptions* temp = optimizer_options_;
  optimizer_options_ = NULL;
  return temp;
}
void GraphOptions::set_allocated_optimizer_options(::tensorflow::OptimizerOptions* optimizer_options) {
  delete optimizer_options_;
  optimizer_options_ = optimizer_options;
  if (optimizer_options) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.GraphOptions.optimizer_options)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int ConfigProto::kDeviceCountFieldNumber;
const int ConfigProto::kIntraOpParallelismThreadsFieldNumber;
const int ConfigProto::kInterOpParallelismThreadsFieldNumber;
const int ConfigProto::kUsePerSessionThreadsFieldNumber;
const int ConfigProto::kPlacementPeriodFieldNumber;
const int ConfigProto::kDeviceFiltersFieldNumber;
const int ConfigProto::kGpuOptionsFieldNumber;
const int ConfigProto::kAllowSoftPlacementFieldNumber;
const int ConfigProto::kLogDevicePlacementFieldNumber;
const int ConfigProto::kGraphOptionsFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

ConfigProto::ConfigProto()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.ConfigProto)
}

void ConfigProto::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  gpu_options_ = const_cast< ::tensorflow::GPUOptions*>(&::tensorflow::GPUOptions::default_instance());
  graph_options_ = const_cast< ::tensorflow::GraphOptions*>(&::tensorflow::GraphOptions::default_instance());
}

ConfigProto::ConfigProto(const ConfigProto& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.ConfigProto)
}

void ConfigProto::SharedCtor() {
    _is_default_instance_ = false;
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  device_count_.SetAssignDescriptorCallback(
      protobuf_AssignDescriptorsOnce);
  device_count_.SetEntryDescriptor(
      &::tensorflow::ConfigProto_DeviceCountEntry_descriptor_);
  intra_op_parallelism_threads_ = 0;
  inter_op_parallelism_threads_ = 0;
  use_per_session_threads_ = false;
  placement_period_ = 0;
  gpu_options_ = NULL;
  allow_soft_placement_ = false;
  log_device_placement_ = false;
  graph_options_ = NULL;
}

ConfigProto::~ConfigProto() {
  // @@protoc_insertion_point(destructor:tensorflow.ConfigProto)
  SharedDtor();
}

void ConfigProto::SharedDtor() {
  if (this != default_instance_) {
    delete gpu_options_;
    delete graph_options_;
  }
}

void ConfigProto::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* ConfigProto::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return ConfigProto_descriptor_;
}

const ConfigProto& ConfigProto::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fframework_2fconfig_2eproto();
  return *default_instance_;
}

ConfigProto* ConfigProto::default_instance_ = NULL;

ConfigProto* ConfigProto::New(::google::protobuf::Arena* arena) const {
  ConfigProto* n = new ConfigProto;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void ConfigProto::Clear() {
#define ZR_HELPER_(f) reinterpret_cast<char*>(\
  &reinterpret_cast<ConfigProto*>(16)->f)

#define ZR_(first, last) do {\
  ::memset(&first, 0,\
           ZR_HELPER_(last) - ZR_HELPER_(first) + sizeof(last));\
} while (0)

  ZR_(intra_op_parallelism_threads_, inter_op_parallelism_threads_);
  ZR_(placement_period_, allow_soft_placement_);
  if (GetArenaNoVirtual() == NULL && gpu_options_ != NULL) delete gpu_options_;
  gpu_options_ = NULL;
  log_device_placement_ = false;
  if (GetArenaNoVirtual() == NULL && graph_options_ != NULL) delete graph_options_;
  graph_options_ = NULL;

#undef ZR_HELPER_
#undef ZR_

  device_count_.Clear();
  device_filters_.Clear();
}

bool ConfigProto::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.ConfigProto)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // map<string, int32> device_count = 1;
      case 1: {
        if (tag == 10) {
          DO_(input->IncrementRecursionDepth());
         parse_loop_device_count:
          ::google::protobuf::scoped_ptr<ConfigProto_DeviceCountEntry> entry(device_count_.NewEntry());
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
              input, entry.get()));
          (*mutable_device_count())[entry->key()] = *entry->mutable_value();
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            entry->key().data(), entry->key().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.ConfigProto.DeviceCountEntry.key"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(10)) goto parse_loop_device_count;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectTag(16)) goto parse_intra_op_parallelism_threads;
        break;
      }

      // optional int32 intra_op_parallelism_threads = 2;
      case 2: {
        if (tag == 16) {
         parse_intra_op_parallelism_threads:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &intra_op_parallelism_threads_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(24)) goto parse_placement_period;
        break;
      }

      // optional int32 placement_period = 3;
      case 3: {
        if (tag == 24) {
         parse_placement_period:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &placement_period_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(34)) goto parse_device_filters;
        break;
      }

      // repeated string device_filters = 4;
      case 4: {
        if (tag == 34) {
         parse_device_filters:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->add_device_filters()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->device_filters(this->device_filters_size() - 1).data(),
            this->device_filters(this->device_filters_size() - 1).length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.ConfigProto.device_filters"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(34)) goto parse_device_filters;
        if (input->ExpectTag(40)) goto parse_inter_op_parallelism_threads;
        break;
      }

      // optional int32 inter_op_parallelism_threads = 5;
      case 5: {
        if (tag == 40) {
         parse_inter_op_parallelism_threads:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &inter_op_parallelism_threads_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(50)) goto parse_gpu_options;
        break;
      }

      // optional .tensorflow.GPUOptions gpu_options = 6;
      case 6: {
        if (tag == 50) {
         parse_gpu_options:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_gpu_options()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(56)) goto parse_allow_soft_placement;
        break;
      }

      // optional bool allow_soft_placement = 7;
      case 7: {
        if (tag == 56) {
         parse_allow_soft_placement:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &allow_soft_placement_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(64)) goto parse_log_device_placement;
        break;
      }

      // optional bool log_device_placement = 8;
      case 8: {
        if (tag == 64) {
         parse_log_device_placement:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &log_device_placement_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(72)) goto parse_use_per_session_threads;
        break;
      }

      // optional bool use_per_session_threads = 9;
      case 9: {
        if (tag == 72) {
         parse_use_per_session_threads:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &use_per_session_threads_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(82)) goto parse_graph_options;
        break;
      }

      // optional .tensorflow.GraphOptions graph_options = 10;
      case 10: {
        if (tag == 82) {
         parse_graph_options:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_graph_options()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.ConfigProto)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.ConfigProto)
  return false;
#undef DO_
}

void ConfigProto::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.ConfigProto)
  // map<string, int32> device_count = 1;
  {
    ::google::protobuf::scoped_ptr<ConfigProto_DeviceCountEntry> entry;
    for (::google::protobuf::Map< ::std::string, ::google::protobuf::int32 >::const_iterator
        it = this->device_count().begin();
        it != this->device_count().end(); ++it) {
      entry.reset(device_count_.NewEntryWrapper(it->first, it->second));
      ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
          1, *entry, output);
      ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
        it->first.data(), it->first.length(),
        ::google::protobuf::internal::WireFormatLite::SERIALIZE,
        "tensorflow.ConfigProto.DeviceCountEntry.key");
    }
  }

  // optional int32 intra_op_parallelism_threads = 2;
  if (this->intra_op_parallelism_threads() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(2, this->intra_op_parallelism_threads(), output);
  }

  // optional int32 placement_period = 3;
  if (this->placement_period() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(3, this->placement_period(), output);
  }

  // repeated string device_filters = 4;
  for (int i = 0; i < this->device_filters_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->device_filters(i).data(), this->device_filters(i).length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.ConfigProto.device_filters");
    ::google::protobuf::internal::WireFormatLite::WriteString(
      4, this->device_filters(i), output);
  }

  // optional int32 inter_op_parallelism_threads = 5;
  if (this->inter_op_parallelism_threads() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(5, this->inter_op_parallelism_threads(), output);
  }

  // optional .tensorflow.GPUOptions gpu_options = 6;
  if (this->has_gpu_options()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      6, *this->gpu_options_, output);
  }

  // optional bool allow_soft_placement = 7;
  if (this->allow_soft_placement() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(7, this->allow_soft_placement(), output);
  }

  // optional bool log_device_placement = 8;
  if (this->log_device_placement() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(8, this->log_device_placement(), output);
  }

  // optional bool use_per_session_threads = 9;
  if (this->use_per_session_threads() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(9, this->use_per_session_threads(), output);
  }

  // optional .tensorflow.GraphOptions graph_options = 10;
  if (this->has_graph_options()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      10, *this->graph_options_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.ConfigProto)
}

::google::protobuf::uint8* ConfigProto::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.ConfigProto)
  // map<string, int32> device_count = 1;
  {
    ::google::protobuf::scoped_ptr<ConfigProto_DeviceCountEntry> entry;
    for (::google::protobuf::Map< ::std::string, ::google::protobuf::int32 >::const_iterator
        it = this->device_count().begin();
        it != this->device_count().end(); ++it) {
      entry.reset(device_count_.NewEntryWrapper(it->first, it->second));
      target = ::google::protobuf::internal::WireFormatLite::
          WriteMessageNoVirtualToArray(
              1, *entry, target);
      ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
        it->first.data(), it->first.length(),
        ::google::protobuf::internal::WireFormatLite::SERIALIZE,
        "tensorflow.ConfigProto.DeviceCountEntry.key");
    }
  }

  // optional int32 intra_op_parallelism_threads = 2;
  if (this->intra_op_parallelism_threads() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(2, this->intra_op_parallelism_threads(), target);
  }

  // optional int32 placement_period = 3;
  if (this->placement_period() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(3, this->placement_period(), target);
  }

  // repeated string device_filters = 4;
  for (int i = 0; i < this->device_filters_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->device_filters(i).data(), this->device_filters(i).length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.ConfigProto.device_filters");
    target = ::google::protobuf::internal::WireFormatLite::
      WriteStringToArray(4, this->device_filters(i), target);
  }

  // optional int32 inter_op_parallelism_threads = 5;
  if (this->inter_op_parallelism_threads() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(5, this->inter_op_parallelism_threads(), target);
  }

  // optional .tensorflow.GPUOptions gpu_options = 6;
  if (this->has_gpu_options()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        6, *this->gpu_options_, target);
  }

  // optional bool allow_soft_placement = 7;
  if (this->allow_soft_placement() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(7, this->allow_soft_placement(), target);
  }

  // optional bool log_device_placement = 8;
  if (this->log_device_placement() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(8, this->log_device_placement(), target);
  }

  // optional bool use_per_session_threads = 9;
  if (this->use_per_session_threads() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(9, this->use_per_session_threads(), target);
  }

  // optional .tensorflow.GraphOptions graph_options = 10;
  if (this->has_graph_options()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        10, *this->graph_options_, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.ConfigProto)
  return target;
}

int ConfigProto::ByteSize() const {
  int total_size = 0;

  // optional int32 intra_op_parallelism_threads = 2;
  if (this->intra_op_parallelism_threads() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int32Size(
        this->intra_op_parallelism_threads());
  }

  // optional int32 inter_op_parallelism_threads = 5;
  if (this->inter_op_parallelism_threads() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int32Size(
        this->inter_op_parallelism_threads());
  }

  // optional bool use_per_session_threads = 9;
  if (this->use_per_session_threads() != 0) {
    total_size += 1 + 1;
  }

  // optional int32 placement_period = 3;
  if (this->placement_period() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int32Size(
        this->placement_period());
  }

  // optional .tensorflow.GPUOptions gpu_options = 6;
  if (this->has_gpu_options()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->gpu_options_);
  }

  // optional bool allow_soft_placement = 7;
  if (this->allow_soft_placement() != 0) {
    total_size += 1 + 1;
  }

  // optional bool log_device_placement = 8;
  if (this->log_device_placement() != 0) {
    total_size += 1 + 1;
  }

  // optional .tensorflow.GraphOptions graph_options = 10;
  if (this->has_graph_options()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->graph_options_);
  }

  // map<string, int32> device_count = 1;
  total_size += 1 * this->device_count_size();
  {
    ::google::protobuf::scoped_ptr<ConfigProto_DeviceCountEntry> entry;
    for (::google::protobuf::Map< ::std::string, ::google::protobuf::int32 >::const_iterator
        it = this->device_count().begin();
        it != this->device_count().end(); ++it) {
      entry.reset(device_count_.NewEntryWrapper(it->first, it->second));
      total_size += ::google::protobuf::internal::WireFormatLite::
          MessageSizeNoVirtual(*entry);
    }
  }

  // repeated string device_filters = 4;
  total_size += 1 * this->device_filters_size();
  for (int i = 0; i < this->device_filters_size(); i++) {
    total_size += ::google::protobuf::internal::WireFormatLite::StringSize(
      this->device_filters(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void ConfigProto::MergeFrom(const ::google::protobuf::Message& from) {
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const ConfigProto* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const ConfigProto>(
          &from);
  if (source == NULL) {
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
    MergeFrom(*source);
  }
}

void ConfigProto::MergeFrom(const ConfigProto& from) {
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  device_count_.MergeFrom(from.device_count_);
  device_filters_.MergeFrom(from.device_filters_);
  if (from.intra_op_parallelism_threads() != 0) {
    set_intra_op_parallelism_threads(from.intra_op_parallelism_threads());
  }
  if (from.inter_op_parallelism_threads() != 0) {
    set_inter_op_parallelism_threads(from.inter_op_parallelism_threads());
  }
  if (from.use_per_session_threads() != 0) {
    set_use_per_session_threads(from.use_per_session_threads());
  }
  if (from.placement_period() != 0) {
    set_placement_period(from.placement_period());
  }
  if (from.has_gpu_options()) {
    mutable_gpu_options()->::tensorflow::GPUOptions::MergeFrom(from.gpu_options());
  }
  if (from.allow_soft_placement() != 0) {
    set_allow_soft_placement(from.allow_soft_placement());
  }
  if (from.log_device_placement() != 0) {
    set_log_device_placement(from.log_device_placement());
  }
  if (from.has_graph_options()) {
    mutable_graph_options()->::tensorflow::GraphOptions::MergeFrom(from.graph_options());
  }
}

void ConfigProto::CopyFrom(const ::google::protobuf::Message& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void ConfigProto::CopyFrom(const ConfigProto& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ConfigProto::IsInitialized() const {

  return true;
}

void ConfigProto::Swap(ConfigProto* other) {
  if (other == this) return;
  InternalSwap(other);
}
void ConfigProto::InternalSwap(ConfigProto* other) {
  device_count_.Swap(&other->device_count_);
  std::swap(intra_op_parallelism_threads_, other->intra_op_parallelism_threads_);
  std::swap(inter_op_parallelism_threads_, other->inter_op_parallelism_threads_);
  std::swap(use_per_session_threads_, other->use_per_session_threads_);
  std::swap(placement_period_, other->placement_period_);
  device_filters_.UnsafeArenaSwap(&other->device_filters_);
  std::swap(gpu_options_, other->gpu_options_);
  std::swap(allow_soft_placement_, other->allow_soft_placement_);
  std::swap(log_device_placement_, other->log_device_placement_);
  std::swap(graph_options_, other->graph_options_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata ConfigProto::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = ConfigProto_descriptor_;
  metadata.reflection = ConfigProto_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// ConfigProto

// map<string, int32> device_count = 1;
int ConfigProto::device_count_size() const {
  return device_count_.size();
}
void ConfigProto::clear_device_count() {
  device_count_.Clear();
}
 const ::google::protobuf::Map< ::std::string, ::google::protobuf::int32 >&
ConfigProto::device_count() const {
  // @@protoc_insertion_point(field_map:tensorflow.ConfigProto.device_count)
  return device_count_.GetMap();
}
 ::google::protobuf::Map< ::std::string, ::google::protobuf::int32 >*
ConfigProto::mutable_device_count() {
  // @@protoc_insertion_point(field_mutable_map:tensorflow.ConfigProto.device_count)
  return device_count_.MutableMap();
}

// optional int32 intra_op_parallelism_threads = 2;
void ConfigProto::clear_intra_op_parallelism_threads() {
  intra_op_parallelism_threads_ = 0;
}
 ::google::protobuf::int32 ConfigProto::intra_op_parallelism_threads() const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.intra_op_parallelism_threads)
  return intra_op_parallelism_threads_;
}
 void ConfigProto::set_intra_op_parallelism_threads(::google::protobuf::int32 value) {
  
  intra_op_parallelism_threads_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.ConfigProto.intra_op_parallelism_threads)
}

// optional int32 inter_op_parallelism_threads = 5;
void ConfigProto::clear_inter_op_parallelism_threads() {
  inter_op_parallelism_threads_ = 0;
}
 ::google::protobuf::int32 ConfigProto::inter_op_parallelism_threads() const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.inter_op_parallelism_threads)
  return inter_op_parallelism_threads_;
}
 void ConfigProto::set_inter_op_parallelism_threads(::google::protobuf::int32 value) {
  
  inter_op_parallelism_threads_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.ConfigProto.inter_op_parallelism_threads)
}

// optional bool use_per_session_threads = 9;
void ConfigProto::clear_use_per_session_threads() {
  use_per_session_threads_ = false;
}
 bool ConfigProto::use_per_session_threads() const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.use_per_session_threads)
  return use_per_session_threads_;
}
 void ConfigProto::set_use_per_session_threads(bool value) {
  
  use_per_session_threads_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.ConfigProto.use_per_session_threads)
}

// optional int32 placement_period = 3;
void ConfigProto::clear_placement_period() {
  placement_period_ = 0;
}
 ::google::protobuf::int32 ConfigProto::placement_period() const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.placement_period)
  return placement_period_;
}
 void ConfigProto::set_placement_period(::google::protobuf::int32 value) {
  
  placement_period_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.ConfigProto.placement_period)
}

// repeated string device_filters = 4;
int ConfigProto::device_filters_size() const {
  return device_filters_.size();
}
void ConfigProto::clear_device_filters() {
  device_filters_.Clear();
}
 const ::std::string& ConfigProto::device_filters(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.device_filters)
  return device_filters_.Get(index);
}
 ::std::string* ConfigProto::mutable_device_filters(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.ConfigProto.device_filters)
  return device_filters_.Mutable(index);
}
 void ConfigProto::set_device_filters(int index, const ::std::string& value) {
  // @@protoc_insertion_point(field_set:tensorflow.ConfigProto.device_filters)
  device_filters_.Mutable(index)->assign(value);
}
 void ConfigProto::set_device_filters(int index, const char* value) {
  device_filters_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set_char:tensorflow.ConfigProto.device_filters)
}
 void ConfigProto::set_device_filters(int index, const char* value, size_t size) {
  device_filters_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:tensorflow.ConfigProto.device_filters)
}
 ::std::string* ConfigProto::add_device_filters() {
  return device_filters_.Add();
}
 void ConfigProto::add_device_filters(const ::std::string& value) {
  device_filters_.Add()->assign(value);
  // @@protoc_insertion_point(field_add:tensorflow.ConfigProto.device_filters)
}
 void ConfigProto::add_device_filters(const char* value) {
  device_filters_.Add()->assign(value);
  // @@protoc_insertion_point(field_add_char:tensorflow.ConfigProto.device_filters)
}
 void ConfigProto::add_device_filters(const char* value, size_t size) {
  device_filters_.Add()->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_add_pointer:tensorflow.ConfigProto.device_filters)
}
 const ::google::protobuf::RepeatedPtrField< ::std::string>&
ConfigProto::device_filters() const {
  // @@protoc_insertion_point(field_list:tensorflow.ConfigProto.device_filters)
  return device_filters_;
}
 ::google::protobuf::RepeatedPtrField< ::std::string>*
ConfigProto::mutable_device_filters() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.ConfigProto.device_filters)
  return &device_filters_;
}

// optional .tensorflow.GPUOptions gpu_options = 6;
bool ConfigProto::has_gpu_options() const {
  return !_is_default_instance_ && gpu_options_ != NULL;
}
void ConfigProto::clear_gpu_options() {
  if (GetArenaNoVirtual() == NULL && gpu_options_ != NULL) delete gpu_options_;
  gpu_options_ = NULL;
}
const ::tensorflow::GPUOptions& ConfigProto::gpu_options() const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.gpu_options)
  return gpu_options_ != NULL ? *gpu_options_ : *default_instance_->gpu_options_;
}
::tensorflow::GPUOptions* ConfigProto::mutable_gpu_options() {
  
  if (gpu_options_ == NULL) {
    gpu_options_ = new ::tensorflow::GPUOptions;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.ConfigProto.gpu_options)
  return gpu_options_;
}
::tensorflow::GPUOptions* ConfigProto::release_gpu_options() {
  
  ::tensorflow::GPUOptions* temp = gpu_options_;
  gpu_options_ = NULL;
  return temp;
}
void ConfigProto::set_allocated_gpu_options(::tensorflow::GPUOptions* gpu_options) {
  delete gpu_options_;
  gpu_options_ = gpu_options;
  if (gpu_options) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.ConfigProto.gpu_options)
}

// optional bool allow_soft_placement = 7;
void ConfigProto::clear_allow_soft_placement() {
  allow_soft_placement_ = false;
}
 bool ConfigProto::allow_soft_placement() const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.allow_soft_placement)
  return allow_soft_placement_;
}
 void ConfigProto::set_allow_soft_placement(bool value) {
  
  allow_soft_placement_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.ConfigProto.allow_soft_placement)
}

// optional bool log_device_placement = 8;
void ConfigProto::clear_log_device_placement() {
  log_device_placement_ = false;
}
 bool ConfigProto::log_device_placement() const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.log_device_placement)
  return log_device_placement_;
}
 void ConfigProto::set_log_device_placement(bool value) {
  
  log_device_placement_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.ConfigProto.log_device_placement)
}

// optional .tensorflow.GraphOptions graph_options = 10;
bool ConfigProto::has_graph_options() const {
  return !_is_default_instance_ && graph_options_ != NULL;
}
void ConfigProto::clear_graph_options() {
  if (GetArenaNoVirtual() == NULL && graph_options_ != NULL) delete graph_options_;
  graph_options_ = NULL;
}
const ::tensorflow::GraphOptions& ConfigProto::graph_options() const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.graph_options)
  return graph_options_ != NULL ? *graph_options_ : *default_instance_->graph_options_;
}
::tensorflow::GraphOptions* ConfigProto::mutable_graph_options() {
  
  if (graph_options_ == NULL) {
    graph_options_ = new ::tensorflow::GraphOptions;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.ConfigProto.graph_options)
  return graph_options_;
}
::tensorflow::GraphOptions* ConfigProto::release_graph_options() {
  
  ::tensorflow::GraphOptions* temp = graph_options_;
  graph_options_ = NULL;
  return temp;
}
void ConfigProto::set_allocated_graph_options(::tensorflow::GraphOptions* graph_options) {
  delete graph_options_;
  graph_options_ = graph_options;
  if (graph_options) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.ConfigProto.graph_options)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

}  // namespace tensorflow

// @@protoc_insertion_point(global_scope)
